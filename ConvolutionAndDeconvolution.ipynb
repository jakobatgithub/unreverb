{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionAndDeconvolution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "mount_file_id": "1SRUKY4yx8QV3in901ypooX29d5Xl-1eH",
      "authorship_tag": "ABX9TyPDnO2wOrEv+4ARXv6bGDYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakobatgithub/unreverb/blob/main/ConvolutionAndDeconvolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rir_generator"
      ],
      "metadata": {
        "id": "9hFRUmeB5ONY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.signal as ss\n",
        "import soundfile as sf\n",
        "import rir_generator as rir\n",
        "from IPython.display import Audio \n",
        "from IPython.core.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# A script to generate the Impulse Response (IR) Functions of a rectangular room\n",
        "# of a given size with given receiver and source positions and given Reverberation time T60.\n",
        "\n",
        "# https://github.com/audiolabs/rir-generator\n",
        "# pip install rir-generator\n",
        "# pip install SoundFile\n",
        "\n",
        "#signal, fs = sf.read(\"bark.wav\", always_2d=True)\n",
        "\n",
        "def my_convolution(IR_data, signal):\n",
        "  # be careful with the order of IR_data and signal!\n",
        "  #return ss.convolve(IR_data, signal, mode='full')\n",
        "  #return ss.convolve(signal, IR_data, mode='same')\n",
        "\treturn ss.convolve(signal, IR_data, mode='valid')\n",
        " \n",
        "def render_history(history):\n",
        "    plt.plot(history[\"loss\"], label=\"loss\")\n",
        "    plt.plot(history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Our losses\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "#samplerate = 2**13\n",
        "samplerate = 8000\n",
        "\n",
        "#reverberation_times = [0.4, 0.6, 0.8]\n",
        "reverberation_times = [0.5]\n",
        "IR_datas = []\n",
        "idx = 0\n",
        "for reverberation_time in reverberation_times:\n",
        "    IR_data = rir.generate(\n",
        "    \tc=340,                  # Sound velocity (m/s)\n",
        "    \tfs=samplerate,                  # Sample frequency (samples/s)\n",
        "    \tr=[                     # Receiver position(s) [x y z] (m)\n",
        "    \t    [2.5, 2, 1.5]\n",
        "    \t],\n",
        "    \ts=[3.0, 2, 1.5],          # Source position [x y z] (m)\n",
        "    \tL=[7, 5, 3],            # Room dimensions [x y z] (m)\n",
        "    \treverberation_time=reverberation_time, # Reverberation time T60 (s)\n",
        "    \tnsample=2*samplerate,           # Number of output samples\n",
        "\t)\n",
        "    print(IR_data.shape)              # (4096, 3)\n",
        "    IR_datas.append(IR_data)\n",
        "    #sf.write('random_IRs/IRF_'+str(idx)+'.wav', IR_data, samplerate)\n",
        "    idx = idx +1\t\n",
        "\n",
        "#print(signal.shape)         # (11462, 2)\n",
        "\n",
        "# Convolve 2-channel signal with 3 impulse responses\n",
        "#signal = ss.convolve(h[:, None, :], signal[:, :, None])\n",
        "\n",
        "#print(signal.shape)         # (15557, 2, 3)"
      ],
      "metadata": {
        "id": "uMHgjjaW5k7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 8*samplerate\n",
        "batch = 10\n",
        "split = batch\n",
        "IR_data = IR_datas[0].T[0]\n",
        "signal = np.random.randn(batch*N)\n",
        "signals = np.array(np.array_split(signal, split))\n",
        "transformed_signals = []\n",
        "for signal in signals:\n",
        "  transformed_signal = my_convolution(IR_data, signal)\n",
        "  transformed_signals.append(transformed_signal)\n",
        "\n",
        "transformed_signals = np.array(transformed_signals)\n",
        "print(signal.shape)\n",
        "print(signals.shape)\n",
        "print(transformed_signal.shape)\n",
        "print(transformed_signals.shape)\n",
        "display(Audio(np.array(signals[0]), rate=samplerate, autoplay=False))\n",
        "display(Audio(np.array(transformed_signals[0]), rate=samplerate, autoplay=False))"
      ],
      "metadata": {
        "id": "x6BYRygm3X2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(signals[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Q3T4jYAFU2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(transformed_signals[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kSXJ3OAuFf-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4yqP0euMknWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "# path of the tensorflow dataset \n",
        "path = '/content/drive/MyDrive/dsr_project/data/but-czas_v1.0/wavs/'\n",
        "\n",
        "# load the tensorflow dataset\n",
        "dataset_F = tf.data.experimental.load(path + \"tf_F_2_randomIRFs_dataset\")\n",
        "dataset_M = tf.data.experimental.load(path + \"tf_M_2_randomIRFs_dataset\")\n",
        "dataset = dataset_F.concatenate(dataset_M)\n",
        "\n",
        "# determine size of the dataset\n",
        "dataset_size = sum(1 for _ in dataset)\n",
        "print(f\"dataset_size: {dataset_size}\")\n",
        "\n",
        "def lambda_1(features, labels, targets):\n",
        "  return (features, labels)\n",
        "\n",
        "def lambda_2(features, labels, targets):\n",
        "  return (features, targets)\n",
        "\n",
        "def lambda_3(features, labels, targets):\n",
        "  return labels\n",
        "\n",
        "# obtain the datasets containing only labels or targets\n",
        "label_dataset = dataset.map(lambda features, labels, targets: lambda_1(features, labels, targets))\n",
        "target_dataset = dataset.map(lambda features, labels, targets: lambda_2(features, labels, targets))\n",
        "\n",
        "# obtain all labels\n",
        "all_labels = dataset.map(lambda features, labels, targets: lambda_3(features, labels, targets))\n",
        "\n",
        "# transform all_labels dataset to numpy array\n",
        "all_labels_np = []\n",
        "for label in all_labels:\n",
        "  all_labels_np.append(tfds.as_numpy(label))\n",
        "\n",
        "all_labels_np = np.array(all_labels_np)\n",
        "\n",
        "# determine unique labels\n",
        "unique_labels, counts = np.unique(all_labels_np, return_counts=True)\n",
        "print(f\"unique_labels: {unique_labels}\")\n",
        "#print(counts)\n",
        "\n",
        "# determine number of unique labels\n",
        "nr_of_unique_labels = unique_labels.shape[0]\n",
        "print(f\"nr_of_unique_labels: {nr_of_unique_labels}\")\n",
        "\n",
        "# shuffle the dataset before splitting in train and validate!\n",
        "label_dataset = label_dataset.shuffle(dataset_size)\n",
        "dataset = dataset.shuffle(dataset_size)\n",
        "\n",
        "# split dataset in train and validate\n",
        "train_fraction = 0.8\n",
        "validate_dataset_size = int(dataset_size * (1.0-train_fraction)) # 20 percent of dataset_size\n",
        "#train_dataset = label_dataset.skip(validate_dataset_size)\n",
        "#validate_dataset = label_dataset.take(validate_dataset_size)\n",
        "\n",
        "# load response functions\n",
        "ir_path = '/content/drive/My Drive/dsr_project/data/random_IRs/'\n",
        "responses_dataset = tf.data.experimental.load(ir_path + \"randomIRFs\")"
      ],
      "metadata": {
        "id": "Vf1bN7tckZ7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X0 = []\n",
        "y0 = []\n",
        "for feature, label, target in dataset:\n",
        "  label = label.numpy()\n",
        "  if label == 3:\n",
        "    a = feature.numpy()[0]\n",
        "    a_max = np.max([abs(np.max(a)), abs(np.min(a))])\n",
        "    a = a / a_max\n",
        "    b = target.numpy()[0]\n",
        "    b_max = np.max([abs(np.max(b)), abs(np.min(b))])\n",
        "    b = b / b_max\n",
        "    X0.append(a)\n",
        "    y0.append(b)\n",
        "\n",
        "split_idx = int(0.8*len(X0))\n",
        "\n",
        "X = np.array(X0)\n",
        "y = np.array(y0)\n",
        "X_train = np.array(X0[:split_idx])\n",
        "y_train = np.array(y0[:split_idx])\n",
        "X_validate = np.array(X0[split_idx + 1:])\n",
        "y_validate = np.array(y0[split_idx + 1:])"
      ],
      "metadata": {
        "id": "cHCJ8FHjyRFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train = np.array(y0[:split_idx])\n",
        "#y_train = np.array(X0[:split_idx])\n",
        "#X_validate = np.array(y0[split_idx + 1:])\n",
        "#y_validate = np.array(X0[split_idx + 1:])"
      ],
      "metadata": {
        "id": "4XDjQzMsN4ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for feature, label, target in dataset.shuffle(dataset_size).take(1):\n",
        "  print(feature.numpy().shape)\n",
        "  display(Audio(feature.numpy()[0], rate=samplerate, autoplay=False))\n",
        "  print(target.numpy().shape)\n",
        "  display(Audio(target.numpy()[0], rate=samplerate, autoplay=False))"
      ],
      "metadata": {
        "id": "aWl1cSrEuWMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Convolution1D\n",
        "\n",
        "model = Sequential([Dense(y.shape[1], input_dim=X.shape[1], use_bias=False, activation=None)])\n",
        "#model = Sequential()\n",
        "#model.add(Dense(10000, input_dim=X.shape[1], use_bias=False, activation=None))\n",
        "#model.add(Dense(y.shape[1], use_bias=False, activation=None))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3QhisDfEndp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.compile(loss='cosine_similarity', optimizer='adam')\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=100, verbose='auto', validation_data=(X_validate, y_validate), shuffle=True)\n",
        "print(\"\\n\")\n",
        "print(f\"history.history['loss'][-1]: {history.history['loss'][-1]}\")\n",
        "print(f\"history.history['val_loss'][-1]: {history.history['val_loss'][-1]}\")\n",
        "render_history(history.history)"
      ],
      "metadata": {
        "id": "IWC20riN81j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 52\n",
        "deconvolved = model.predict(X_validate)\n",
        "ass = []\n",
        "for a in deconvolved:\n",
        "    a_max = np.max([abs(np.max(a)), abs(np.min(a))])\n",
        "    a = a / a_max\n",
        "    ass.append(a)\n",
        "\n",
        "deconvolved = np.array(ass)\n",
        "display(Audio(y_validate[idx], rate=samplerate, autoplay=False))\n",
        "display(Audio(X_validate[idx], rate=samplerate, autoplay=False))\n",
        "display(Audio(deconvolved[idx], rate=samplerate, autoplay=False))\n",
        "plt.plot(deconvolved[idx], 'b')\n",
        "plt.plot(y_validate[idx], 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FxJCWXDS0lKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce"
      ],
      "metadata": {
        "id": "FfrSFlHGCxKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import noisereduce as nr\n",
        "deconvolved_filtered = nr.reduce_noise(y=deconvolved[idx], sr=samplerate)\n",
        "display(Audio(deconvolved[idx], rate=samplerate, autoplay=False))\n",
        "display(Audio(deconvolved_filtered, rate=samplerate, autoplay=False))\n",
        "plt.plot(deconvolved[idx], 'b')\n",
        "plt.plot(deconvolved_filtered, 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BV6P6G_8DNtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(X_validate[idx], 'b')\n",
        "plt.plot(y_validate[idx], 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lm_6r5IBAJyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(y_validate[idx]-deconvolved[idx], 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AhqIZQLN_Thi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 150\n",
        "deconvolved = model.predict(X_train)\n",
        "ass = []\n",
        "for a in deconvolved:\n",
        "    a_max = np.max([abs(np.max(a)), abs(np.min(a))])\n",
        "    a = a / a_max\n",
        "    ass.append(a)\n",
        "\n",
        "deconvolved = np.array(ass)\n",
        "display(Audio(y_train[idx], rate=samplerate, autoplay=False))\n",
        "display(Audio(X_train[idx], rate=samplerate, autoplay=False))\n",
        "display(Audio(deconvolved[idx], rate=samplerate, autoplay=False))\n",
        "plt.plot(deconvolved[idx], 'b')\n",
        "plt.plot(y_train[idx], 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FQkrPhGws8Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.fft import fft, ifft, ifftshift\n",
        "\n",
        "lambd_est = 1e-3\n",
        "fft(signal)\n",
        "def wiener_deconvolution(signal, kernel, lambd):\n",
        "  \"lambd is the SNR\"\n",
        "  kernel = np.hstack((kernel, np.zeros(len(signal) - len(kernel)))) # zero pad the kernel to same length\n",
        "  H = fft(kernel)\n",
        "  Y = fft(signal)\n",
        "  S = np.abs(fft(signal))**2\n",
        "  #deconvolved = np.real(ifft(Y*np.conj(H)*S/(H*np.conj(H)*S + lambd**2)))\n",
        "  GY = Y*np.conj(H)/(H*np.conj(H) + lambd**2)\n",
        "  deconvolved = np.real(ifft(GY))\n",
        "  return deconvolved"
      ],
      "metadata": {
        "id": "RlRoahzh0kHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start_idx = np.max(np.where(IR_data == 0.0)[0]) + 1\n",
        "#print(start_idx)\n",
        "ir_data = IR_data\n",
        "ir_max = np.max([abs(np.max(ir_data)), abs(np.min(ir_data))])\n",
        "#ir_data = ir_data / ir_max\n",
        "for features, targets in target_dataset.take(1):\n",
        "  signal = targets.numpy()[0]\n",
        "  signal_max = np.max([abs(np.max(signal)), abs(np.min(signal))])\n",
        "  signal = signal / signal_max\n",
        "  print(f\"signal.shape: {signal.shape}, max: {np.max(signal)}, min: {np.min(signal)}\")\n",
        "  print(f\"ir_data.shape: {ir_data.shape}, max: {np.max(ir_data)}, min: {np.min(ir_data)}\")\n",
        "  convolved_signal = ss.convolve(IR_data, signal, mode='valid')\n",
        "  convolved_signal_max = np.max([abs(np.max(convolved_signal)), abs(np.min(convolved_signal))])\n",
        "  convolved_signal = convolved_signal / convolved_signal_max\n",
        "  print(f\"convolved_signal.shape: {convolved_signal.shape}, max: {np.max(convolved_signal)}, min: {np.min(convolved_signal)}\")\n",
        "\n",
        "\n",
        "#deconvolved_signal, residue = ss.deconvolve(signal, ir_data[start_idx:])\n",
        "#deconvolved_signal = wiener_deconvolution(signal, ir_data[start_idx:],  lambd=1e-0)  \n",
        "deconvolved_signal = wiener_deconvolution(signal, ir_data,  lambd = 1.0*1e-0)\n",
        "deconvolved_signal_max = np.max([abs(np.max(deconvolved_signal)), abs(np.min(deconvolved_signal))])\n",
        "deconvolved_signal = deconvolved_signal / deconvolved_signal_max\n",
        "print(f\"deconvolved_signal.shape: {deconvolved_signal.shape}, max: {np.max(deconvolved_signal)}, min: {np.min(deconvolved_signal)}\")\n",
        "display(Audio(signal, rate=8000))\n",
        "display(Audio(convolved_signal, rate=8000))  \n",
        "display(Audio(deconvolved_signal, rate=8000))  "
      ],
      "metadata": {
        "id": "6L9Uf1tXk2An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(signal[19000:20000], 'b')\n",
        "#plt.plot(convolved_signal[19000:20000], 'g')\n",
        "plt.plot(deconvolved_signal[19000:20000], 'r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RCBij00JB95x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal_psd = np.abs(np.fft.fft(signal))**2\n",
        "plt.plot(signal_psd)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PS--Lcy7KYP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal_psd.shape"
      ],
      "metadata": {
        "id": "U7hCmSZ7NCg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, signal_psd = ss.welch(signal, samplerate)\n",
        "plt.plot(signal_psd)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pJAwFC0pJClf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal_psd.shape"
      ],
      "metadata": {
        "id": "VWdNXGF7J6Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(-10, 10, 1):\n",
        "  lambd = 10.0**(i/10.0)\n",
        "  deconvolved_signal = wiener_deconvolution(signal, ir_data,  lambd)  \n",
        "  print(f\"lambda: {lambd}, RMS: {np.sqrt(np.mean((signal - deconvolved_signal) ** 2))}\")"
      ],
      "metadata": {
        "id": "T6RP2q-SAbPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import rir_generator as rir\n",
        "from IPython.display import Audio \n",
        "from IPython.core.display import display\n",
        "from numpy.fft import fft, ifft\n",
        "\n",
        "\n",
        "audiopath = '/content/drive/MyDrive/dsr_project/data/but-czas_v1.0/wavs/F-22-02/F-22-02-003.wav'\n",
        "irpath = '/content/drive/MyDrive/dsr_project/data/arthur-sykes-rymer-auditorium-university-york/b-format/s1r2.wav'\n",
        "\n",
        "sample_rate = 24000\n",
        "\n",
        "audio, audio_sample_rate = librosa.load(audiopath, sr=sample_rate) # Downsample 24kHz\n",
        "IR, IR_sample_rate = librosa.load(irpath, sr=sample_rate) # Downsample 24kHz\n",
        "\n",
        "print(f\"audio_sample_rate: {audio_sample_rate}, audio.shape: {audio.shape}, max: {np.max(audio)}, min: {np.min(audio)}\")\n",
        "print(f\"IR_sample_rate: {IR_sample_rate}, IR.shape: {IR.shape}, max: {np.max(IR)}, min: {np.min(IR)}\")\n",
        "display(Audio(audio, rate=sample_rate))\n",
        "display(Audio(IR, rate=sample_rate))\n",
        "plt.plot(audio)\n",
        "plt.show()\n",
        "plt.plot(IR)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nm0nZ4C9VC-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lambd_est = 1e-3\n",
        "\n",
        "def wiener_deconvolution(signal, kernel, lambd=lambd_est):\n",
        "  kernel = np.hstack((kernel, np.zeros(len(signal) - len(kernel)))) # zero pad the kernel to same length\n",
        "  H = fft(kernel)\n",
        "  Y = fft(signal)\n",
        "  S = np.abs(fft(signal))**2\n",
        "  GY = Y*np.conj(H)*S/(H*np.conj(H)*S + lambd**2)\n",
        "  #GY = Y*np.conj(H)/(H*np.conj(H) + lambd**2)\n",
        "  deconvolved = np.real(ifft(GY))\n",
        "  return deconvolved"
      ],
      "metadata": {
        "id": "Y1XNR5a-bs-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IR_padded = np.hstack((IR, np.zeros(len(audio) - len(IR))))\n",
        "audio_reverb = np.real(ifft(fft(IR_padded)*fft(audio)))\n",
        "deconvolved = wiener_deconvolution(audio_reverb, IR, lambd=0.0)\n",
        "print(f\"max: {np.max(deconvolved)}, min: {np.min(deconvolved)}\")\n",
        "display(Audio(audio[:2*sample_rate], rate=sample_rate))\n",
        "display(Audio(audio_reverb[:2*sample_rate], rate=sample_rate))\n",
        "display(Audio(deconvolved[:2*sample_rate], rate=sample_rate))\n",
        "delta = audio - deconvolved\n",
        "print(f\"max: {np.max(delta)}, min: {np.min(delta)}, msd: {np.sqrt(np.square(delta).mean()})\")\n",
        "plt.plot(delta[:2*sample_rate])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "61R2N5CNZ_X1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mes = []\n",
        "for expo in range(-10, 10, 1):\n",
        "  deconvolved = wiener_deconvolution(audio_reverb, IR, lambd=10**(expo))\n",
        "  mes.append([10**(expo), np.sqrt(np.square(np.subtract(deconvolved, audio)).mean())])\n",
        "\n",
        "mes"
      ],
      "metadata": {
        "id": "bnE8wKdmfgea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IR = rir.generate(\n",
        "    \tc=340,                  # Sound velocity (m/s)\n",
        "    \tfs=sample_rate,                  # Sample frequency (samples/s)\n",
        "    \tr=[                     # Receiver position(s) [x y z] (m)\n",
        "    \t    [2.5, 2, 1.5]\n",
        "    \t],\n",
        "    \ts=[3.0, 2, 1.5],          # Source position [x y z] (m)\n",
        "    \tL=[7, 5, 3],            # Room dimensions [x y z] (m)\n",
        "    \treverberation_time=1.2, # Reverberation time T60 (s)\n",
        "    \tnsample=2*sample_rate,           # Number of output samples\n",
        "\t)\n",
        "IR = IR[:,0]\n",
        "\n",
        "IR_padded = np.hstack((IR, np.zeros(len(audio) - len(IR))))\n",
        "audio_reverb = np.real(ifft(fft(IR_padded)*fft(audio)))\n",
        "deconvolved = wiener_deconvolution(audio_reverb, IR, lambd=0.0)"
      ],
      "metadata": {
        "id": "JhfDxmHJi1ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"max: {np.max(deconvolved)}, min: {np.min(deconvolved)}\")\n",
        "display(Audio(audio[:2*sample_rate], rate=sample_rate))\n",
        "display(Audio(audio_reverb[:2*sample_rate], rate=sample_rate))\n",
        "display(Audio(deconvolved[:2*sample_rate], rate=sample_rate))\n",
        "delta = audio - deconvolved\n",
        "print(f\"max: {np.max(delta)}, min: {np.min(delta)}, mse: {np.square(delta).mean()}\")\n",
        "plt.plot(delta[:2*sample_rate])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gwsmWrUHjj39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mes = []\n",
        "for expo in range(-10, 10, 1):\n",
        "  deconvolved = wiener_deconvolution(audio_reverb, IR, lambd=10**(expo))\n",
        "  mes.append([10**(expo), np.sqrt(np.square(np.subtract(deconvolved, audio)).mean())])\n",
        "\n",
        "mes"
      ],
      "metadata": {
        "id": "1461_3z3k1Vd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}