{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreprocessAndSaveData_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakobatgithub/unreverb/blob/main/PreprocessAndSaveData_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FlbhZHXidBAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "path = '/content/drive/My Drive/dsr_project/data/HarvardWordList/'\n",
        "save_path = path + 'datasets/'\n",
        "audiopaths = glob.glob(path + '*.wav')\n",
        "audiopaths"
      ],
      "metadata": {
        "id": "-JCZXqmQzRIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "path = '/content/drive/My Drive/dsr_project/data/but-czas_v1.0/'\n",
        "save_path = path + 'datasets/'\n",
        "audiopaths = glob.glob(path + 'wavs/*/F*.wav')\n",
        "audiopaths"
      ],
      "metadata": {
        "id": "wpMV6-Lj25nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "ir_base_path = '/content/drive/My Drive/dsr_project/data/samplicity-ir/'\n",
        "#irpaths = glob.glob(ir_base_path + '*Rooms*[0]2*/*M-to-S.wav')\n",
        "irpaths = glob.glob(ir_base_path + '*/*M-to-S.wav')\n",
        "irpaths"
      ],
      "metadata": {
        "id": "O3QMpLwOsgM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is done here:\n",
        "#   we load the audio data without reverb - the input\n",
        "#   we load the impulse response (IR) functions\n",
        "#   we generate the audio data with reverb by convolving all impulse response functions with all audio data without reverb\n",
        "#   we transform all data to tensorflow datasets\n",
        "#   one can solve two different tasks:\n",
        "#     classification: which impulse response function is used\n",
        "#     regression: remove the reverb from the input\n",
        "#   correspondingly, we can generate two different datasets here:\n",
        "#     one with the labels (consequtive numbers of the IRs) as the targets for classification\n",
        "#     one with the audios without reverb as the targets (commented out)\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio \n",
        "from IPython.core.display import display\n",
        "from numpy.fft import fft, ifft\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os, shutil\n",
        "\n",
        "# sampling rate for resampling\n",
        "sample_rate = 2**14\n",
        "\n",
        "# all audio input should have the same length\n",
        "# we split all audio data into chunks of length n\n",
        "# n = 2*sample_rate corresponds to 2 seconds\n",
        "# correspondingly, all audio data without reverb must be at least 2 seconds long\n",
        "n = sample_rate\n",
        "\n",
        "#save_path = '/content/drive/My Drive/dsr_project/data/HarvardWordList/datasets/'\n",
        "\n",
        "# paths for audio without reverb\n",
        "#audiopaths = ['/content/drive/My Drive/dsr_project/data/HarvardWordList/SIHarvardWordListsFemale.wav',\n",
        "#              '/content/drive/My Drive/dsr_project/data/HarvardWordList/SIHarvardWordListsMale.wav']\n",
        "\n",
        "# paths to IR functions\n",
        "#irpaths = [\"/content/drive/My Drive/dsr_project/data/r1-nuclear-reactor-hall/b-format/r1_bformat.wav\", \n",
        "#           \"/content/drive/My Drive/dsr_project/data/arthur-sykes-rymer-auditorium-university-york/b-format/s1r2.wav\",\n",
        "#           \"/content/drive/My Drive/dsr_project/data/trollers-gill/b-format/dales_site1_1way_bformat.wav\"]\n",
        "\n",
        "# function to delete all content in a folder\n",
        "def delete_folder_contents(folder):\n",
        "  for filename in os.listdir(folder):\n",
        "      file_path = os.path.join(folder, filename)\n",
        "      try:\n",
        "          if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "              os.unlink(file_path)\n",
        "          elif os.path.isdir(file_path):\n",
        "              shutil.rmtree(file_path)\n",
        "      except Exception as e:\n",
        "          print('Failed to delete %s. Reason: %s' % (file_path, e))  \n",
        "\n",
        "# function to convolve IRs with audio\n",
        "def my_conv(signal, kernel):\n",
        "  kernel_padded = np.hstack((kernel, np.zeros(len(signal) - len(kernel))))\n",
        "  convolved_signal = np.real(ifft(fft(kernel_padded)*fft(signal)))\n",
        "  return convolved_signal\n",
        "\n",
        "# function to deconvolve IRs from audio\n",
        "def wiener_deconvolution(signal, kernel, lambd=1e-3):\n",
        "  kernel = np.hstack((kernel, np.zeros(len(signal) - len(kernel)))) # zero pad the kernel to same length\n",
        "  H = fft(kernel)\n",
        "  Y = fft(signal)\n",
        "  #S = np.abs(fft(signal))**2\n",
        "  #GY = Y*np.conj(H)*S/(H*np.conj(H)*S + lambd**2)\n",
        "  GY = Y*np.conj(H)/(H*np.conj(H) + lambd**2)\n",
        "  deconvolved = np.real(ifft(GY))\n",
        "  return deconvolved\n",
        "\n",
        "\n",
        "# placeholder lists\n",
        "audios = []\n",
        "audio_chunks = []\n",
        "\n",
        "# loop over all audiofiles without reverb\n",
        "for audiopath in audiopaths:\n",
        "  # load audio without reverb \n",
        "  audio, audio_sample_rate = librosa.load(audiopath, sr=sample_rate)\n",
        "  #print(f\"audio.shape[0]: {audio.shape[0]}\")\n",
        "\n",
        "  # collect alls audio without reverb in a list\n",
        "  audios.append(audio)\n",
        "\n",
        "  # split audio into chunks\n",
        "  split_audio = np.split(audio[:n*int(len(audio)//n)], int(len(audio)//n))\n",
        "  split_audio = np.asarray(split_audio)\n",
        "\n",
        "  # collect all audio chunks in a list\n",
        "  audio_chunks.extend(split_audio)\n",
        "\n",
        "# transform list to numpy array\n",
        "audio_chunks = np.asarray(audio_chunks)  \n"
      ],
      "metadata": {
        "id": "Yk7ft818Y90Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we convolve all audios with all IRs\n",
        "\n",
        "# delete all content in save_path\n",
        "#delete_folder_contents(save_path)\n",
        "\n",
        "# check if there are already tf datasets\n",
        "dataset_filenames = glob.glob(save_path + 'tf_IR_*')\n",
        "labels = np.asarray([int(filename.split('_')[-1]) for filename in dataset_filenames])\n",
        "\n",
        "# counter for irpaths\n",
        "if labels.shape[0] > 0:\n",
        "  iridx = np.max(labels) + 1\n",
        "else:\n",
        "  iridx = 0\n",
        "\n",
        "# placeholder lists\n",
        "irs = []\n",
        "reverb_audios = []\n",
        "\n",
        "for irpath in irpaths:\n",
        "  \n",
        "  print(f\"iridx: {iridx}\")\n",
        "\n",
        "  # placeholder list\n",
        "  reverb_audio_chunks = []\n",
        "\n",
        "  # load IR functions\n",
        "  #ir_raw, _ = my_get_ir_sample(irpath, resample=sample_rate)\n",
        "  ir, IR_sample_rate = librosa.load(irpath, sr=sample_rate)\n",
        "  \n",
        "  # shorten all IR functions to the same length\n",
        "  #ir = ir[0:int(sample_rate*2.0)]\n",
        "      \n",
        "  # collect IRs in a list\n",
        "  irs.append(ir)\n",
        "    \n",
        "  # loop over all audios without reverb\n",
        "  # counter for audios\n",
        "  audioidx = 0\n",
        "  for audio in audios:\n",
        "\n",
        "    # convole audio without reverb with IRs to obtain audio with reverb\n",
        "    reverb_audio = my_conv(audio, ir)\n",
        "    #print(f\"reverb_audio.shape[1]: {reverb_audio.shape[1]}\")\n",
        "      \n",
        "    # collect audios with reverb in a list\n",
        "    reverb_audios.append(reverb_audio)\n",
        "\n",
        "    # split audio into chunks\n",
        "    split_reverb_audio = np.split(reverb_audio[:n*int(len(reverb_audio)//n)], int(len(reverb_audio)//n))\n",
        "    split_reverb_audio = np.asarray(split_reverb_audio)\n",
        "\n",
        "    reverb_audio_chunks.extend(split_reverb_audio)\n",
        "    \n",
        "    # increase counter for audios\n",
        "    audioidx = audioidx + 1\n",
        "\n",
        "  # transform list to numpy array\n",
        "  reverb_audio_chunks = np.asarray(reverb_audio_chunks)  \n",
        "  \n",
        "  features = reverb_audio_chunks\n",
        "  targets = audio_chunks\n",
        "  label = iridx\n",
        "  labels = np.full(features.shape[0], label)\n",
        "  print(f\"features.shape: {features.shape}\")\n",
        "  print(f\"targets.shape: {targets.shape}\")\n",
        "  print(f\"labels.shape: {labels.shape}\")\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((features, labels, targets))\n",
        "  #dataset = tf.data.Dataset.from_tensor_slices((features, targets))\n",
        "  \n",
        "  # save the data as tensorflow dataset\n",
        "  tf.data.experimental.save(dataset, save_path + 'tf_IR_' + str(iridx))\n",
        "  tot_save_path = save_path + 'IR_' + str(iridx) + '_' + irpaths[0].split('/')[-1]\n",
        "  #!cp \"$irpath\" \"$tot_save_path\"\n",
        "  shutil.copy(irpath, tot_save_path)\n",
        "\n",
        "  # increase counter for irpaths\n",
        "  iridx = iridx + 1"
      ],
      "metadata": {
        "id": "KErcslplB-WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_idx = 1\n",
        "ir_idx = 1\n",
        "reverb_idx = ir_idx*len(audios) + audio_idx\n",
        "deconvolved = wiener_deconvolution(reverb_audios[reverb_idx], irs[ir_idx])\n",
        "display(Audio(audios[audio_idx][:10*sample_rate], rate=sample_rate))\n",
        "display(Audio(reverb_audios[reverb_idx][:10*sample_rate], rate=sample_rate))\n",
        "display(Audio(deconvolved[:10*sample_rate], rate=sample_rate))"
      ],
      "metadata": {
        "id": "7_j2tUFJZ-sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_length = len(audios)\n",
        "ir_length = len(irs)\n",
        "for audio_idx in range(audio_length):\n",
        "  for ir_idx in range(ir_length):\n",
        "    reverb_idx = ir_idx*audio_length + audio_idx\n",
        "    print(f\"audio_idx: {audio_idx}, ir_idx: {ir_idx}, reverb_idx: {ir_idx*audio_length + audio_idx}\")"
      ],
      "metadata": {
        "id": "FqD27U_tyZUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "dataset_filenames = glob.glob(save_path + 'tf_IR_*')\n",
        "labels = [int(filename.split('_')[-1]) for filename in dataset_filenames]\n",
        "print(f\"labels: {labels}\")\n",
        "\n",
        "target_datasets = []\n",
        "for dataset_filename in dataset_filenames:\n",
        "  # load the tensorflow dataset\n",
        "  target_datasets.append(tf.data.experimental.load(dataset_filename))\n",
        "\n",
        "target_dataset = target_datasets[0]\n",
        "for i in range(2, len(target_datasets)):\n",
        "  target_dataset = target_dataset.concatenate(target_datasets[i])\n",
        "\n",
        "# determine size of the dataset\n",
        "dataset_size = sum(1 for _ in target_dataset)\n",
        "print(f\"dataset_size: {dataset_size}\")"
      ],
      "metadata": {
        "id": "pBTMrkeftFEE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}